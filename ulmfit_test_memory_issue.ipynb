{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#tokenization \n",
    "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
    "\n",
    "#remove stop-words\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#de-tokenization\n",
    "\n",
    "detokenized_doc = []\n",
    "for i in range(len(df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "    \n",
    "df['text'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6788, 2), (4526, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#language model data\n",
    "data_lm = TextLMDataBunch.from_df(train_df=df_trn, valid_df=df_val, path = \"\")\n",
    "\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING LANGUAGE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3)\n",
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train the learner object with learning rate = 1e-2\n",
    "# learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(10, 1e-2, moms=(0.8,0.7)) #decrease learning rate by a factor of 10? why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('ft_enc')\n",
    "# learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))  \n",
    "learn.save('clas_first')\n",
    "learn.load('clas_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "# learn.save('clas_first') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('clas_first')\n",
    "# learn.freeze_to(-2)\n",
    "# learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7))  #decrease learning rate by a factor of 10? \n",
    "# learn.save('clas_first_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('clas_first_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.freeze_to(-3)\n",
    "# learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7))  #decrease learning rate to middle of spike down? (factor of 10?)\n",
    "# learn.save('clas_first_3')\n",
    "#MEMORY ALLOCATION ERROR https://github.com/fastai/fastai/issues/1979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (6788 items)\n",
       "x: TextList\n",
       "xxbos xxup cnn claimed bought semi automatic assault rifles xxmaj and say xxmaj koresh god like xxmaj he managed buy build collection fully automatic semi automatic rifles xxmaj quite feat i would say xxmaj they still making charges sexual abuse course xxmaj nobody seems noticed xxmaj treasury department nothing sex crimes xxmaj or maybe feds recently instituted xxup tax sex crimes xxmaj yeah xxup batf looking unregistered guns weapon gun fighting i also heard claiming cautious xxmaj koresh heated ammunition stockpile i seem recall smokeless powder tends decompose even moderate temperatures i would rather surprised fire nature stockpile xxunk xxunk i seem recall aluminum powder common component xxunk xxmaj the folks rec xxunk could probably tell i think anything legal proper license xxmaj if xxunk relics permit i believe could legally xxunk go launcher xxmaj charles xxmaj scripter cescript phy mtu edu xxmaj dept xxmaj physics xxmaj michigan xxmaj tech xxmaj houghton xxup mi,xxbos xxmaj hi i looking help choosing package high speed silicon xxup adc xxmaj mhz currently fabricated xxmaj this phd research project i test chip speed xxup pcb i expect roughly packaged circuits xxup dc low speed high speed testing using different set ups test chip i know sure xxup dip work long lead lines high inductance xxmaj getting custom made package expensive i trying choose xxunk leadless chip carrier xxmaj the xxunk would hard test since soldered test setup i would spend loads time soldering i kept changing test chip xxmaj the leadless chip carrier sockets also long lead lines may work high speeds xxmaj does anyone experience knowledge field i would greatly appreciate help xxmaj any ideas names companies manufacturing holders sockets packages would help p s xxmaj the multi layer fancy gaas packages seem like bit overkill,xxbos i really understand i watched satellite network feeds perhaps people died eyes two xxmaj xxunk fanned flames xxup fbi stopped xxunk gate xxmaj something xxup very wrong scene xxmaj perhaps i watched xxup rambo movies i might xxunk pain fellow humans dying xxmaj thank xxup god i still feel i sorry xxmaj for think got deserved xxmaj can really believe xxmaj even xxmaj koresh xxunk mad man said others deserve fate xxmaj if fact mad even reason believe duped followers therefore innocent brainwashed victims xxmaj is xxunk justifies death xxmaj and clear deaths would occured xxup batf xxup fucked xxup up initially xxup fbi got xxunk pushed xxmaj xxunk edge xxmaj and buy latest version story hook line xxunk i believed along could let live embarrassment xxup batf xxup fbi would severe xxmaj remember suspicion tax evasion warrant xxmaj there witnesses except xxup fbi xxmaj all information filtered xxup fbi xxmaj all allow one remote controlled pool camera installed near building press could done job would able back xxup fbi story close video xxunk risk press xxmaj unless want public see something xxmaj the complete lack source information xxup fbi really causes concern xxmaj sick stomach getting xxunk xxmaj government apologists jmd handheld com,xxbos xxmaj however nothing motorcycling unless consider xxmaj xxunk bike,xxbos i novell i sell upgraded xxmaj the novell complete documentation network cards except xxup id card\n",
       "y: CategoryList\n",
       "16,12,16,8,6\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4526 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and still wonder stereotype us,xxbos i member xxup nra several years recently joined xxup hci i wanted see paid minimum get membership i also sent xxup nra another,xxbos i seen much info add extra internal disk mac xxmaj we would like try i wonder someone good advice xxmaj we xxmaj mac iicx original internal xxmaj quantum xxup mb hard disk unusable floppy drive xxmaj we also new spare xxmaj connor xxup mb disk would like use xxmaj the idea replace broken floppy drive new hard disk seems problems xxmaj the internal xxup scsi cable power cable inside cx connectors one single hard disk drive xxmaj if i made ribbon cable power cable three connectors motherboard disks would work xxmaj is iicx able supply extra power extra disk xxmaj what xxunk i suppose remove resistor packs disk closest motherboard leave installed disk xxmaj the xxup scsi xxup id jumpers also changed new disk gets xxup id xxmaj the old one xxup id xxmaj it problem us remove floppy drive external floppy use boot hard disk xxmaj thank,xxbos hell ios xxunk xxunk sp,xxbos a question regarding xxmaj islamic view towards homosexuality came discussion group i participate i like ask question xxmaj what xxmaj islamic view towards homosexuality\n",
       "y: CategoryList\n",
       "8,16,4,6,19\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(29830, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(29830, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa32903f488>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (6788 items)\n",
       "x: TextList\n",
       "xxbos xxup cnn claimed bought semi automatic assault rifles xxmaj and say xxmaj koresh god like xxmaj he managed buy build collection fully automatic semi automatic rifles xxmaj quite feat i would say xxmaj they still making charges sexual abuse course xxmaj nobody seems noticed xxmaj treasury department nothing sex crimes xxmaj or maybe feds recently instituted xxup tax sex crimes xxmaj yeah xxup batf looking unregistered guns weapon gun fighting i also heard claiming cautious xxmaj koresh heated ammunition stockpile i seem recall smokeless powder tends decompose even moderate temperatures i would rather surprised fire nature stockpile xxunk xxunk i seem recall aluminum powder common component xxunk xxmaj the folks rec xxunk could probably tell i think anything legal proper license xxmaj if xxunk relics permit i believe could legally xxunk go launcher xxmaj charles xxmaj scripter cescript phy mtu edu xxmaj dept xxmaj physics xxmaj michigan xxmaj tech xxmaj houghton xxup mi,xxbos xxmaj hi i looking help choosing package high speed silicon xxup adc xxmaj mhz currently fabricated xxmaj this phd research project i test chip speed xxup pcb i expect roughly packaged circuits xxup dc low speed high speed testing using different set ups test chip i know sure xxup dip work long lead lines high inductance xxmaj getting custom made package expensive i trying choose xxunk leadless chip carrier xxmaj the xxunk would hard test since soldered test setup i would spend loads time soldering i kept changing test chip xxmaj the leadless chip carrier sockets also long lead lines may work high speeds xxmaj does anyone experience knowledge field i would greatly appreciate help xxmaj any ideas names companies manufacturing holders sockets packages would help p s xxmaj the multi layer fancy gaas packages seem like bit overkill,xxbos i really understand i watched satellite network feeds perhaps people died eyes two xxmaj xxunk fanned flames xxup fbi stopped xxunk gate xxmaj something xxup very wrong scene xxmaj perhaps i watched xxup rambo movies i might xxunk pain fellow humans dying xxmaj thank xxup god i still feel i sorry xxmaj for think got deserved xxmaj can really believe xxmaj even xxmaj koresh xxunk mad man said others deserve fate xxmaj if fact mad even reason believe duped followers therefore innocent brainwashed victims xxmaj is xxunk justifies death xxmaj and clear deaths would occured xxup batf xxup fucked xxup up initially xxup fbi got xxunk pushed xxmaj xxunk edge xxmaj and buy latest version story hook line xxunk i believed along could let live embarrassment xxup batf xxup fbi would severe xxmaj remember suspicion tax evasion warrant xxmaj there witnesses except xxup fbi xxmaj all information filtered xxup fbi xxmaj all allow one remote controlled pool camera installed near building press could done job would able back xxup fbi story close video xxunk risk press xxmaj unless want public see something xxmaj the complete lack source information xxup fbi really causes concern xxmaj sick stomach getting xxunk xxmaj government apologists jmd handheld com,xxbos xxmaj however nothing motorcycling unless consider xxmaj xxunk bike,xxbos i novell i sell upgraded xxmaj the novell complete documentation network cards except xxup id card\n",
       "y: CategoryList\n",
       "16,12,16,8,6\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4526 items)\n",
       "x: TextList\n",
       "xxbos xxmaj and still wonder stereotype us,xxbos i member xxup nra several years recently joined xxup hci i wanted see paid minimum get membership i also sent xxup nra another,xxbos i seen much info add extra internal disk mac xxmaj we would like try i wonder someone good advice xxmaj we xxmaj mac iicx original internal xxmaj quantum xxup mb hard disk unusable floppy drive xxmaj we also new spare xxmaj connor xxup mb disk would like use xxmaj the idea replace broken floppy drive new hard disk seems problems xxmaj the internal xxup scsi cable power cable inside cx connectors one single hard disk drive xxmaj if i made ribbon cable power cable three connectors motherboard disks would work xxmaj is iicx able supply extra power extra disk xxmaj what xxunk i suppose remove resistor packs disk closest motherboard leave installed disk xxmaj the xxup scsi xxup id jumpers also changed new disk gets xxup id xxmaj the old one xxup id xxmaj it problem us remove floppy drive external floppy use boot hard disk xxmaj thank,xxbos hell ios xxunk xxunk sp,xxbos a question regarding xxmaj islamic view towards homosexuality came discussion group i participate i like ask question xxmaj what xxmaj islamic view towards homosexuality\n",
       "y: CategoryList\n",
       "8,16,4,6,19\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(29830, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(29830, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fa32903f488>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(29830, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(29830, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=None)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(29830, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(29830, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('clas_first_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7))  #decrease lr slightly further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
